# -*- coding: utf-8 -*-
"""Prakriti.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H4IdVpHlAT12f34ItNfPyySqGrcBtINv

**Importing important libraries and Data**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

from google.colab import files
uploaded = files.upload()

data = pd.read_excel('Data_set.xlsx', index_col=0)
data

"""**Data Preprocessing**"""

data.isnull().sum()

print(data.shape)

data.dtypes

count_str=0
count_float=0
count_int=0
index_lis = []
for item in list(data['TC (%)']):
  if type(item)==str:
    for val in list(data.index):
      if data.loc[val]['TC (%)']==item:
        index_lis.append(val)
    count_str=count_str+1
  elif type(item)==int:
    count_int=count_int+1
  elif type(item)==float:
    count_float=count_float+1    

print(count_float, count_int, count_str)
print(index_lis)

data.drop(index_lis, axis=0, inplace=True)
data

data['TN (%)'] = data['TN (%)'].astype(float)
data['TC (%)'] = data['TC (%)'].astype(float)

data.dtypes

y1 = data['TC (%)']
y1_scaled = y1/100
y1_scaled.head()

y2 = data['TN (%)']
y2_scaled = y2/100
y2_scaled.head()

"""**Model building using only elemental data(highlighted in green)**"""

X1 = data[['Zn', 'S', 'K', 'Ca', 'Ti', 'Mn', 'Fe', 'Rb', 'Sr', 'Al', 'Si']]

X1.head()

corrmat1 = X1.corr(method='pearson')
corrmat1

"""***Finding Correlated Features with correlation > 0.85***"""

correlated_features1 = []
for i in range(len(corrmat1.index)):
    for j in range(i):
        if abs(corrmat1.iloc[i, j])>0.85:
            correlated_features1.append(corrmat1.columns[j])

list_of_correlated_features1 = list(set(correlated_features1))
print('List of one element among two correlated features =', list_of_correlated_features1)
print('Length of above list =', len(list_of_correlated_features1))

"""***Removing Correlted Features***"""

X1_corr = X1.drop(list_of_correlated_features1, axis=1)
X1_corr

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
X1_scaled=scaler.fit_transform(X1)

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
X1_scaled_corr=scaler.fit_transform(X1_corr)

X1_scaled.shape

X1_scaled_corr.shape

"""***Machine Learning Models***

****Linear Regression Model****
"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
model_first_1 = LinearRegression()
kf = cross_val_score(model_first_1, X1_scaled_corr, y1_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
model_first_1 = LinearRegression()
kf = cross_val_score(model_first_1, X1_scaled_corr, y2_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

"""****Decision Tree Regression Model****"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score
model_first_2 = DecisionTreeRegressor(max_depth=2, min_samples_split=5, random_state=42)
kf = cross_val_score(model_first_2, X1_scaled_corr, y1_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score
model_first_2 = DecisionTreeRegressor(max_depth=2, min_samples_split=5, random_state=42)
kf = cross_val_score(model_first_2, X1_scaled_corr, y2_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

"""****Gradient Boosting Regressor Model****"""

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import cross_val_score
model_first_3 = GradientBoostingRegressor(learning_rate=1, max_depth=2, min_samples_split=5, n_estimators=300, random_state=42)
kf = cross_val_score(model_first_3, X1_scaled_corr, y1_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import cross_val_score
model_first_3 = GradientBoostingRegressor(learning_rate=1, max_depth=2, min_samples_split=5, n_estimators=300, random_state=42)
kf = cross_val_score(model_first_3, X1_scaled_corr, y2_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

"""**Model building using only  Spectral data(not highlighted)**"""

X2 = data.drop(['TC (%)', 'TN (%)', 'Zn', 'S', 'K', 'Ca', 'Ti', 'Mn', 'Fe', 'Rb', 'Sr', 'Al', 'Si'], axis = 1)

corrmat2 = X2.corr(method='pearson')
corrmat2

corrmat2.shape

"""***Finding correlated features with correlation > 0.9***"""

correlated_features2 = []
for i in range(len(corrmat2.index)):
    for j in range(i):
        if abs(corrmat2.iloc[i, j])>0.9:
            correlated_features2.append(corrmat2.columns[j])

list_of_correlated_features2 = list(set(correlated_features2))
print('List of one element among two correlated features =', list_of_correlated_features2)
print('Length of above list =', len(list_of_correlated_features2))

"""***Removing Correlted Features***"""

X2_corr = X2.drop(list_of_correlated_features2, axis=1)
X2_corr

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
X2_scaled=scaler.fit_transform(X2)

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
X2_scaled_corr=scaler.fit_transform(X2_corr)

X2_scaled.shape

X2_scaled_corr.shape

"""***Machine Learning Models***

****Linear Regression Model****
"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
model_second_1 = LinearRegression()
kf = cross_val_score(model_second_1, X2_scaled_corr, y1_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
model_second_1 = LinearRegression()
kf = cross_val_score(model_second_1, X2_scaled_corr, y2_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

"""****Decision Tree Regressor Model****"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score
model_second_2 = DecisionTreeRegressor(max_depth=2, min_samples_split=5, random_state=42)
kf = cross_val_score(model_second_2, X2_scaled_corr, y1_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score
model_first_2 = DecisionTreeRegressor(max_depth=2, min_samples_split=5, random_state=42)
kf = cross_val_score(model_first_2, X2_scaled_corr, y2_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

"""****Gradient Boosting Regressor Model****"""

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import cross_val_score
model_second_3 = GradientBoostingRegressor(learning_rate=1, max_depth=2, min_samples_split=5, n_estimators=300, random_state=42)
kf = cross_val_score(model_second_3, X2_scaled_corr, y1_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import cross_val_score
model_second_3 = GradientBoostingRegressor(learning_rate=1, max_depth=2, min_samples_split=5, n_estimators=300, random_state=42 )
kf = cross_val_score(model_second_3, X2_scaled_corr, y2_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

"""***Model building using whole dataset***"""

X3 = data.drop(['TC (%)', 'TN (%)'], axis=1)

corrmat3 = X3.corr(method='pearson')
corrmat3

corrmat3.shape

"""***Finding correlated features with correlation > 0.9***"""

correlated_features3 = []
for i in range(len(corrmat3.index)):
    for j in range(i):
        if abs(corrmat3.iloc[i, j])>0.9:
            correlated_features3.append(corrmat3.columns[j])

list_of_correlated_features3 = list(set(correlated_features3))
print('List of one element among two correlated features =', list_of_correlated_features3)
print('Length of above list =', len(list_of_correlated_features3))

"""***Removing Correlted Features***"""

X3_corr = X3.drop(list_of_correlated_features3, axis=1)
X3_corr

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
X3_scaled=scaler.fit_transform(X3)

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
X3_scaled_corr=scaler.fit_transform(X3_corr)

X3_scaled.shape

X3_scaled_corr.shape

"""***Machine Learning Models***

****Linear Regression Model****
"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
model_third_1 = LinearRegression()
kf = cross_val_score(model_third_1, X3_scaled_corr, y1_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score
model_second_1 = LinearRegression()
kf = cross_val_score(model_third_1, X3_scaled_corr, y2_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

"""****Decision Tree Regressor Model****"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score
model_third_2 = DecisionTreeRegressor(max_depth=2, min_samples_split=5,  random_state=42)
kf = cross_val_score(model_third_2, X3_scaled_corr, y1_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score
model_third_2 = DecisionTreeRegressor(max_depth=2, min_samples_split=5,  random_state=42)
kf = cross_val_score(model_third_2, X3_scaled_corr, y2_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

"""****Gradient Boosting Regressor Model****"""

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import cross_val_score
model_third_3 = GradientBoostingRegressor(learning_rate=1, max_depth=2, min_samples_split=5, n_estimators=300,  random_state=42)
kf = cross_val_score(model_third_3, X3_scaled_corr, y1_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import cross_val_score
model_third_3 = GradientBoostingRegressor(learning_rate=1, max_depth=2, min_samples_split=5, n_estimators=300,  random_state=42)
kf = cross_val_score(model_third_3, X3_scaled_corr, y2_scaled, scoring='neg_root_mean_squared_error', cv=5)
kf = -1*np.array(kf)
print("Root mean squared error in each fold = ", kf)
print("Averaage Root mean squared error = ", np.mean(kf))

